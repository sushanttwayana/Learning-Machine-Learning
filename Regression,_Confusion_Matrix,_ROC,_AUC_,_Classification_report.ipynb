{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMX2MMG6Pg+Pa5hKJTBSiwS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sushanttwayana/Learning-Machine-Learning/blob/main/Regression%2C_Confusion_Matrix%2C_ROC%2C_AUC_%2C_Classification_report.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1EkgI4wDUtzQ"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Create X and y arrays\n",
        "# Drop the target variable \"sales\" to define features X\n",
        "X = sales_df.drop(\"sales\", axis=1).values\n",
        "y = sales_df[\"sales\"].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Instantiate the model\n",
        "reg = LinearRegression()\n",
        "\n",
        "# Fit the model to the data\n",
        "reg.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = reg.predict(X_test)\n",
        "print(\"Predictions: {}, Actual Values: {}\".format(y_pred[:2], y_test[:2]))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import mean_squared_error\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Compute R-squared\n",
        "r_squared = reg.score(X_test, y_test)\n",
        "\n",
        "# Compute RMSE\n",
        "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
        "\n",
        "# Print the metrics\n",
        "print(\"R^2: {}\".format(r_squared))\n",
        "print(\"RMSE: {}\".format(rmse))"
      ],
      "metadata": {
        "id": "p_HjJgDDV-io"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CROSS MODEL VALIDATION**"
      ],
      "metadata": {
        "id": "E3BZXy2LpLUZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary modules\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "\n",
        "# Create a KFold object\n",
        "kf = KFold(n_splits=6, shuffle=True, random_state=5)\n",
        "\n",
        "reg = LinearRegression()\n",
        "\n",
        "# Compute 6-fold cross-validation scores\n",
        "cv_scores = cross_val_score(reg, X, y, cv=kf)\n",
        "\n",
        "# Print scores\n",
        "print(cv_scores)"
      ],
      "metadata": {
        "id": "SQsB-F0ZpQ3K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice how R-squared for each fold ranged between 0.74 and 0.77? By using cross-validation, we can see how performance varies depending on how the data is split!"
      ],
      "metadata": {
        "id": "aAfKyTSspbOc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the mean\n",
        "print(np.mean(cv_results))\n",
        "\n",
        "# Print the standard deviation\n",
        "print(np.std(cv_results))\n",
        "\n",
        "# Print the 95% confidence interval\n",
        "print(np.quantile(cv_results, [0.025, 0.975]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "collapsed": true,
        "id": "mgqsc46Qpdu8",
        "outputId": "59de1d4e-ea1e-4c32-e225-c4c79eb32d13"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'np' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-13e816631470>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Print the mean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Print the standard deviation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reguralization"
      ],
      "metadata": {
        "id": "YaNqVFIe9GXi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Ridge\n",
        "from sklearn.linear_model import Ridge\n",
        "alphas = [0.1, 1.0, 10.0, 100.0, 1000.0, 10000.0]\n",
        "ridge_scores = []\n",
        "for alpha in alphas:\n",
        "\n",
        "  # Create a Ridge regression model\n",
        "  ridge = Ridge(alpha = alpha)\n",
        "  # Fit the data\n",
        "  ridge.fit(X_train, y_train)\n",
        "\n",
        "  # Obtain R-squared\n",
        "  score =ridge.score(X_test, y_test)\n",
        "  ridge_scores.append(score)\n",
        "print(ridge_scores)"
      ],
      "metadata": {
        "id": "AxDdOE9T8-BM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The scores don't appear to change much as alpha increases, which is indicative of how well the features explain the variance in the target—even by heavily penalizing large coefficients, underfitting does not occur!"
      ],
      "metadata": {
        "id": "ZQESHiFC8-Xy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Lasso\n",
        "from sklearn.linear_model import Lasso\n",
        "\n",
        "# Instantiate a lasso regression model\n",
        "lasso = Lasso(alpha = 0.3)\n",
        "\n",
        "# Fit the model to the data\n",
        "X = sales_df.drop(\"sales\", axis =1).values\n",
        "\n",
        "y = sales_df[\"sales\"].values\n",
        "\n",
        "# Compute and print the coefficients\n",
        "lasso_coef = lasso.fit(X,y).coef_\n",
        "print(lasso_coef)\n",
        "plt.bar(sales_columns, lasso_coef)\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dRZCtxL09Kbp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "See how the figure makes it clear that expenditure on TV advertising is the most important feature in the dataset to\n",
        " predict sales values! In the next chapter, we will learn how to further assess and improve our model's performance!"
      ],
      "metadata": {
        "id": "S-VzUPBM-8iD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Confusion Matrix\n"
      ],
      "metadata": {
        "id": "SRhF1bVURXSH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import confusion matrix\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=6)\n",
        "\n",
        "# Fit the model to the training data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)\n",
        "\n",
        "knn.fit(X_train, y_train)\n",
        "# Predict the labels of the test data: y_pred\n",
        "y_pred = knn.predict(X_test)\n",
        "\n",
        "# Generate the confusion matrix and classification report\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "PmB-8T6o-9yT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Excellent! The model produced 34 true positives and 35 false positives, meaning precision was less than 50%, which is confirmed in the classification report. The output also shows a better F1-score for the zero class, which represents individuals who do not have diabetes."
      ],
      "metadata": {
        "id": "0TvgrDcFRUQo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LOGISTIC REGRESSION**"
      ],
      "metadata": {
        "id": "EF9z5hicZ0LY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import LogisticRegression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Instantiate the model\n",
        "logreg = LogisticRegression()\n",
        "\n",
        "# Fit the model\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 3, random_state = 42)\n",
        "\n",
        "logreg.fit(X_train, y_train)\n",
        "# y_pred = logreg.predict(X_test)\n",
        "\n",
        "# Predict probabilities\n",
        "y_pred_probs = logreg.predict_proba(X_test)[:,1]\n",
        "\n",
        "print(y_pred_probs[:10])"
      ],
      "metadata": {
        "id": "JQndmVnGXzJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Smu7Iva6Zx-Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nicely done! Notice how the probability of a diabetes diagnosis for the first 10 individuals in the test set ranges from 0.01 to 0.79. Now let's plot the ROC curve to visualize performance using different thresholds."
      ],
      "metadata": {
        "id": "x2WlyHXzX0CB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import roc_curve\n",
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "# Generate ROC curve values: false positive rate, true positive rate, thresholds\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred_probs)\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "\n",
        "# Plot tpr against fpr\n",
        "plt.plot(fpr, tpr)\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve for Diabetes Prediction')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DQvHYT-wX27w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import roc_auc_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "\n",
        "# Calculate roc_auc_score\n",
        "print(roc_auc_score(y_test, y_pred_probs))\n",
        "\n",
        "# Calculate the confusion matrix\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "# Calculate the classification report\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "F_c-prZXYr8C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " The ROC curve is above the dotted line, so the model performs better than randomly guessing the class of each observation.\n",
        "\n",
        " Did you notice that logistic regression performs better than the KNN model across all the metrics you calculated? A ROC AUC score of 0.8002 means this model is 60% better than a chance model at correctly predicting labels! scikit-learn makes it easy to produce several classification metrics with only a few lines of code"
      ],
      "metadata": {
        "id": "ZjNYhRyfZWNx"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qc9N7L6EZXFx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}